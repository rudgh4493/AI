1017
다음주 목요일 2시~2시50분
626호 이자리 학번 홀수
628호 옆옆방 학번 짝수


4~5문제
자료나 읽거나 처리하는건 안나옴 -그림그리는거

주로 알고리즘에서 중심을 이루는 api를 어떻게 쓰냐
괄호채우기

텐서플로우 패키지사용하니까 이론은 사용안함

몇번 읽어보시길 바랍니다.


시험범위 했던거
이미지 6개 
맞춤설정	텐서 및 작업
생성 		신경스타일 전이 	딥드림 	자동인코더	변이자동인코더


python	numpy ndarray 
tensor	tf.op			더빠름




맞춤설정	-	텐서 및 작업	-	시험에 안나옴

텐서

파이선 넘파이로 들어오는데 텐서를 사용하면 더 속도가 빠름

x = tf.linalg.matmul([[1]], [[2, 3]])
print(x)
print(x.shape)
print(x.dtype)

NumPy 배열과 tf.Tensor의 가장 확연한 차이는 다음과 같습니다:

텐서는 가속기 메모리(GPU, TPU와 같은)에서 사용할 수 있습니다.
텐서는 불변성(immutable)을 가집니다.



NumPy 호환성
TensorFlow tf.Tensor와 NumPy ndarray 사이의 변환은 간단합니다.

텐서플로 연산은 자동으로 NumPy 배열을 텐서로 변환합니다.
NumPy 연산은 자동으로 텐서를 NumPy 배열로 변환합니다.
print(tensor.numpy())


GPU가속 X

==텐서라는 자료형이 있다.




전시간에 한거 	이미지를 텐서로 만든다 - 경사하강법
			스타일맞추고 콘텐트 유지하고

@tf.function()
def train_step(image):
  with tf.GradientTape() as tape:
    outputs = extractor(image)
    loss = style_content_loss(outputs)

  grad = tape.gradient(loss, image)
  opt.apply_gradients([(grad, image)])
  image.assign(clip_0_1(image))




딥드림	신경망이 학습한 패턴을 시각화하는 실험


특성 추출 모델 (feature extraction model) 준비하기
# Maximize the activations of these layers
names = ['mixed3', 'mixed5']
layers = [base_model.get_layer(name).output for name in names]

# Create the feature extraction model
dream_model = tf.keras.Model(inputs=base_model.input, outputs=layers) <--



손실 계산하기
def calc_loss(img, model):
  # Pass forward the image through the model to retrieve the activations.
  # Converts the image into a batch of size 1.
  img_batch = tf.expand_dims(img, axis=0)
  layer_activations = model(img_batch)
  if len(layer_activations) == 1:
    layer_activations = [layer_activations]

  losses = []
  for act in layer_activations:			<--
    loss = tf.math.reduce_mean(act)			
    losses.append(loss)

  return  tf.reduce_sum(losses)



경사상승법
class DeepDream(tf.Module):
  def __init__(self, model):
    self.model = model

  @tf.function(
      input_signature=(
        tf.TensorSpec(shape=[None,None,3], dtype=tf.float32),
        tf.TensorSpec(shape=[], dtype=tf.int32),
        tf.TensorSpec(shape=[], dtype=tf.float32),)
  )
  def __call__(self, img, steps, step_size):
      print("Tracing")
      loss = tf.constant(0.0)
      for n in tf.range(steps):		<--
        with tf.GradientTape() as tape:
          # This needs gradients relative to `img`
          # `GradientTape` only watches `tf.Variable`s by default
          tape.watch(img)
          loss = calc_loss(img, self.model)

        # Calculate the gradient of the loss with respect to the pixels of the input image.
        gradients = tape.gradient(loss, img)

        # Normalize the gradients.
        gradients /= tf.math.reduce_std(gradients) + 1e-8 

        # In gradient ascent, the "loss" is maximized so that the input image increasingly "excites" the layers.
        # You can update the image by directly adding the gradients (because they're the same shape!)
        img = img + gradients*step_size
        img = tf.clip_by_value(img, -1, 1)

      return loss, img




주 루프
def run_deep_dream_simple(img, steps=100, step_size=0.01):
  # Convert from uint8 to the range expected by the model.
  img = tf.keras.applications.inception_v3.preprocess_input(img)
  img = tf.convert_to_tensor(img)
  step_size = tf.convert_to_tensor(step_size)
  steps_remaining = steps
  step = 0
  while steps_remaining:
    if steps_remaining>100:
      run_steps = tf.constant(100)
    else:
      run_steps = tf.constant(steps_remaining)
    steps_remaining -= run_steps
    step += run_steps

    loss, img = deepdream(img, run_steps, tf.constant(step_size))		<--

    display.clear_output(wait=True)
    show(deprocess(img))
    print ("Step {}, loss {}".format(step, loss))


  result = deprocess(img)
  display.clear_output(wait=True)
  show(result)

  return result


옥타브 올라가기



시험예시
미분하는방법	미분을 어떻게 구하는지	적용을 어떻게 하는지	아무튼이런부분 중점으로 공부
예시, def: __call__





